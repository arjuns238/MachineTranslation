{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMzOvf2y/Fq6UAb5cQW4Lgh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjuns238/MachineTranslation/blob/main/MachineTranslation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdoKzChr3DqN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import multi30k, Multi30k\n",
        "from torch.utils.data import Dataset, DataLoader,random_split\n",
        "from typing import Iterable, List\n",
        "import torchtext\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Installing dependencies\n",
        "# !pip install -U torchdata\n",
        "# !pip install -U spacy\n",
        "!pip install 'portalocker>=2.0.0'\n",
        "# !python -m spacy download en_core_web_sm\n",
        "!python -m spacy download fr_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euelWWGW4DW9",
        "outputId": "54cee4ac-0504-446f-9e51-d29381e392f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n",
            "Collecting fr-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.5)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "block_size = 128\n",
        "learning_rate = 1e-2\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "eval_iters = 200\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "n_embd = 384\n",
        "dropout = 0.2\n",
        "no_of_heads = 6\n",
        "n_layer = 6\n",
        "device\n",
        "SRC_LANGUAGE = 'Fr'\n",
        "TGT_LANGUAGE = 'En'\n",
        "device"
      ],
      "metadata": {
        "id": "1oMLIZgl3Joe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "438675aa-1549-4d16-fc95-80a602d5d58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/eng-fra.txt\", sep=\"\\t\", header=None)\n",
        "data = data.set_axis(['En','Fr'], axis = 1) # Rename indices\n",
        "data.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UBZLUOIp3Ltw",
        "outputId": "84d91c15-acbf-409f-f61a-76226fb30ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                       En  \\\n",
              "135837  A carbon footprint is the amount of carbon dio...   \n",
              "135838  Death is something that we're often discourage...   \n",
              "135839  Since there are usually multiple websites on a...   \n",
              "135840  If someone who doesn't know your background sa...   \n",
              "135841  It may be impossible to get a completely error...   \n",
              "\n",
              "                                                       Fr  \n",
              "135837  Une empreinte carbone est la somme de pollutio...  \n",
              "135838  La mort est une chose qu'on nous décourage sou...  \n",
              "135839  Puisqu'il y a de multiples sites web sur chaqu...  \n",
              "135840  Si quelqu'un qui ne connaît pas vos antécédent...  \n",
              "135841  Il est peut-être impossible d'obtenir un Corpu...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9d79d3e-8076-4426-aac2-16b86bcd09d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>En</th>\n",
              "      <th>Fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>135837</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135838</th>\n",
              "      <td>Death is something that we're often discourage...</td>\n",
              "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135839</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135840</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135841</th>\n",
              "      <td>It may be impossible to get a completely error...</td>\n",
              "      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9d79d3e-8076-4426-aac2-16b86bcd09d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9d79d3e-8076-4426-aac2-16b86bcd09d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9d79d3e-8076-4426-aac2-16b86bcd09d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bdf8befd-4eb8-4d1e-880f-8733a6d45e4f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bdf8befd-4eb8-4d1e-880f-8733a6d45e4f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bdf8befd-4eb8-4d1e-880f-8733a6d45e4f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"En\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\",\n          \"It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning, we might be able to minimize errors.\",\n          \"Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"La mort est une chose qu'on nous d\\u00e9courage souvent de discuter ou m\\u00eame de penser mais j'ai pris conscience que se pr\\u00e9parer \\u00e0 la mort est l'une des choses que nous puissions faire qui nous investit le plus de responsabilit\\u00e9. R\\u00e9fl\\u00e9chir \\u00e0 la mort clarifie notre vie.\",\n          \"Il est peut-\\u00eatre impossible d'obtenir un Corpus compl\\u00e8tement d\\u00e9nu\\u00e9 de fautes, \\u00e9tant donn\\u00e9e la nature de ce type d'entreprise collaborative. Cependant, si nous encourageons les membres \\u00e0 produire des phrases dans leurs propres langues plut\\u00f4t que d'exp\\u00e9rimenter dans les langues qu'ils apprennent, nous pourrions \\u00eatre en mesure de r\\u00e9duire les erreurs.\",\n          \"Puisqu'il y a de multiples sites web sur chaque sujet, je clique d'habitude sur le bouton retour arri\\u00e8re lorsque j'atterris sur n'importe quelle page qui contient des publicit\\u00e9s surgissantes. Je me rends juste sur la prochaine page propos\\u00e9e par Google et esp\\u00e8re tomber sur quelque chose de moins irritant.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='fr_core_news_sm')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "# helper function to yield list of tokens\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter[language]:\n",
        "        yield token_transform[language](data_sample)\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    print(ln)\n",
        "    # Training data Iterator\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(data, ln),\n",
        "                                                    min_freq=1,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)\n",
        "\n",
        "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS6lnvtw3OKh",
        "outputId": "a1213a09-8778-4aa1-930e-9ea4008ebc88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fr\n",
            "En\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab_transform[\"En\"].lookup_token(200))\n",
        "print(vocab_transform[\"En\"].lookup_indices([\"left\"]))\n",
        "vocab_size_src = len(vocab_transform[SRC_LANGUAGE])\n",
        "vocab_size_tgt = len(vocab_transform[TGT_LANGUAGE])\n",
        "print(f\"Vocab size for {SRC_LANGUAGE} = {vocab_size_src}\")\n",
        "print(f\"Vocab size for {TGT_LANGUAGE} = {vocab_size_tgt}\")"
      ],
      "metadata": {
        "id": "4GlvmB6N3RP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e6f5bf-b6e5-40fe-dfe2-8b84bb844e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "left\n",
            "[200]\n",
            "Vocab size for Fr = 24554\n",
            "Vocab size for En = 14875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Encode a sentence\n",
        "def encode_sentence(sentence: str, language: str, tokenizer, vocab) -> List[int]:\n",
        "    # Tokenize the sentence\n",
        "    tokens = tokenizer(sentence)\n",
        "    # Convert tokens to indices using vocabulary\n",
        "    indices = vocab_transform[language].lookup_indices(tokens)\n",
        "    return indices\n",
        "\n",
        "# Step 2: Decode a sequence\n",
        "def decode_sequence(indices: List[int], language: str, vocab) -> str:\n",
        "    # Convert indices to tokens\n",
        "    tokens = [vocab_transform[language].lookup_token(index) for index in indices]\n",
        "    # Remove <bos> and <eos> tokens if present\n",
        "    if tokens[0] == '<bos>':\n",
        "        tokens = tokens[1:]\n",
        "    if tokens[-1] == '<eos>':\n",
        "        tokens = tokens[:-1]\n",
        "    # Convert tokens to a sentence\n",
        "    sentence = \"\"\n",
        "    for token in tokens:\n",
        "        if token == '<bos>' or  token == '<eos>' or token == '<pad>':\n",
        "            continue\n",
        "        sentence = sentence + \" \" + token\n",
        "    return sentence\n",
        "\n",
        "# Example usage\n",
        "sentence = \"Je suis froid\"\n",
        "encoded = encode_sentence(sentence, SRC_LANGUAGE, token_transform[SRC_LANGUAGE], vocab_transform[SRC_LANGUAGE])\n",
        "decoded = decode_sequence(encoded, SRC_LANGUAGE, vocab_transform[SRC_LANGUAGE])\n",
        "print(\"Original sentence:\", sentence)\n",
        "print(\"Encoded sequence:\", encoded)\n",
        "print(\"Decoded sentence:\", decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B2aBecu3ZXu",
        "outputId": "21fa6414-15d5-406d-bd9b-f3fd6bd8edc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence: Je suis froid\n",
            "Encoded sequence: [6, 34, 448]\n",
            "Decoded sentence:  Je suis froid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_sample = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n",
        "        src_sample = src_sample[:block_size]\n",
        "        tgt_sample = text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\"))\n",
        "        tgt_sample = tgt_sample[:block_size]\n",
        "        src_batch.append(src_sample)\n",
        "        tgt_batch.append(tgt_sample)\n",
        "\n",
        "        # src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        # tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "\n",
        "    return src_batch.T, tgt_batch.T"
      ],
      "metadata": {
        "id": "K530InMa3br6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen = data[\"Fr\"][0]\n",
        "sen = data[\"En\"][0]\n",
        "\n",
        "print(sen)\n",
        "outputText = text_transform[TGT_LANGUAGE](sen.rstrip(\"\\n\"))\n",
        "engText = text_transform[SRC_LANGUAGE](sen.rstrip(\"\\n\"))\n",
        "\n",
        "print(outputText)\n",
        "print(engText)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu8cT3jefz-J",
        "outputId": "02207dbe-4d3d-44f4-afe5-b7e484d2419b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\n",
            "tensor([  2, 572,   4,   3])\n",
            "tensor([2, 0, 4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, inputText, outputText):\n",
        "        self.inputText = inputText\n",
        "        self.outputText = outputText\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputText)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.inputText[idx]\n",
        "        outputText = self.outputText[idx]\n",
        "        return x, outputText\n",
        "\n",
        "dataset = CustomDataset(data[\"Fr\"], data[\"En\"])\n"
      ],
      "metadata": {
        "id": "VHHPSEEv3epu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataset:\n",
        "    print(\"x = \", x)\n",
        "    print(\"y = \", y)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrhwjMSwfchZ",
        "outputId": "f76f5190-984b-48dc-95b2-211b4a01058e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =  Va !\n",
            "y =  Go.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, validation split\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create a DataLoader to iterate over batches of data and performing preprocessing - By default produces batch first\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn = collate_fn, shuffle=False)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, collate_fn = collate_fn)"
      ],
      "metadata": {
        "id": "XD6-Dd2wY2CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for x, y in train_dataloader:\n",
        "    print(x.shape)\n",
        "    for src in x:\n",
        "        print(\"X input\", decode_sequence(src, SRC_LANGUAGE, vocab_transform[SRC_LANGUAGE]))\n",
        "        # print(\"Y input\", decode_sequence(tgt, TGT_LANGUAGE, vocab_transform[TGT_LANGUAGE]))\n",
        "    print(\"y shape = \", y.shape)\n",
        "    for item in y:\n",
        "        print(\"Y labels\", decode_sequence(item.T, TGT_LANGUAGE, vocab_transform[TGT_LANGUAGE]))\n",
        "    if i == 1:\n",
        "        break\n",
        "    i += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCY4E-m0S1-v",
        "outputId": "30ad990a-aa62-4a03-9ef3-2ddef09d5191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 19])\n",
            "X input  Tu as l' air superbe dans cette robe .\n",
            "X input  Il n' y a aucun intérêt à rester ici .\n",
            "X input  J' ai un rencard .\n",
            "X input  Les lignes rouges sur la carte représentent les chemins de fer .\n",
            "X input  Elle a toujours fait de son mieux pour leur rendre la vie plus facile .\n",
            "X input  À quoi t' attendais - tu ?\n",
            "X input  Je les déteste tous .\n",
            "X input  Un changement de décor ne serait vraiment pas du luxe , pour moi !\n",
            "X input  Elle veut me tuer .\n",
            "X input  Eh bien , Tom , vous aviez raison .\n",
            "X input  Il a pu réussir l' examen .\n",
            "X input  On s' est débrouillé pour être là - bas à temps .\n",
            "X input  Je ne veux pas être choisie .\n",
            "X input  J' espère vraiment que vous allez apprécier le reste de votre journée .\n",
            "X input  Il l' essaya encore et encore .\n",
            "X input  C' est à peu près tout ce qu' il te faut savoir .\n",
            "X input  J' ai du travail à faire , alors va - t' en et laisse -moi tranquille .\n",
            "X input  Elle suggéra que je l' emmène au zoo .\n",
            "X input  Tu es arrivé vite .\n",
            "X input  Vous mentez mal .\n",
            "X input  Joues - tu bien au tennis ?\n",
            "X input  Vous ne m' aidez pas .\n",
            "X input  Dis bonjour à ta femme , s' il te plaît .\n",
            "X input  Prends ce médicament après chaque repas .\n",
            "X input  Me rendriez -vous un service ?\n",
            "X input  Ne faites pas comme si vous ne saviez pas danser !\n",
            "X input  Fais -moi part de tous les détails !\n",
            "X input  Ces cadeaux sont pour toi .\n",
            "X input  J’ ai beaucoup réfléchi à ce que tu as dis .\n",
            "X input  Mon frère tomba de l' arbre et se cassa une jambe .\n",
            "X input  Je ne peux pas vraiment en discuter .\n",
            "X input  Ça me semble familier .\n",
            "X input  Elle ne m' a pas dit la vérité .\n",
            "X input  Allons nous bourrer la gueule comme on a fait le week - end dernier .\n",
            "X input  Tu peux emporter un parapluie si tu en as besoin d' un .\n",
            "X input  Tu ne devrais pas y aller .\n",
            "X input  Mère Thérésa était une sœur catholique qui vivait et travaillait à Calcutta en Inde .\n",
            "X input  Je me demande si un humain sera jamais répliqué .\n",
            "X input  Je suis maintenant prêt , Tom .\n",
            "X input  Rester à la maison est barbant .\n",
            "X input  J' ai acheté une bouteille de bière au marchand de vin .\n",
            "X input  Ce semestre , j' ai collé deux de mes étudiants pour plagiat .\n",
            "X input  Tu devrais y aller .\n",
            "X input  Le Sahara est le plus grand désert du monde .\n",
            "X input  Quel temps fait -il   ?\n",
            "X input  Je ne veux pas qu' on me dise quoi faire .\n",
            "X input  Il me faut un peu d' aide , là .\n",
            "X input  C' est un type étrange .\n",
            "X input  Réfléchis - y et dis -moi ce que tu décides .\n",
            "X input  As - tu tout préparé pour demain ?\n",
            "X input  Les cars , à la campagne , ne sont habituellement pas à l' heure .\n",
            "X input  Je n' arrive pas à me rappeler de mon mot de passe .\n",
            "X input  N' es - tu pas encore habillé ?\n",
            "X input  C' est une étudiante qui étudie sérieusement .\n",
            "X input  Une femme étendait son linge sur une corde .\n",
            "X input  Merci beaucoup pour l' invitation .\n",
            "X input  Le couteau n' est pas aiguisé .\n",
            "X input  C' est vous la professeur .\n",
            "X input  Il est temps pour nous d' y aller .\n",
            "X input  J' ai attendu toute la nuit .\n",
            "X input  Autrefois , je rêvais pouvoir respirer sous l' eau .\n",
            "X input  Il nous faudra reporter le match .\n",
            "X input  Un jeune homme nous demanda s' il pouvait réussir comme orateur .\n",
            "X input  Les soldats échappèrent à la mort de justesse .\n",
            "y shape =  torch.Size([64, 17])\n",
            "Y labels  You look gorgeous in that dress .\n",
            "Y labels  There is no advantage in staying here .\n",
            "Y labels  I have a date .\n",
            "Y labels  The red lines on the map represent railway lines .\n",
            "Y labels  She has always done her best to make their life easier .\n",
            "Y labels  What were you expecting ?\n",
            "Y labels  I dislike all of them .\n",
            "Y labels  I could really use a change in scenery !\n",
            "Y labels  She wants to kill me .\n",
            "Y labels  Well , Tom , you were right .\n",
            "Y labels  He was able to pass the exam .\n",
            "Y labels  We managed to get there on time .\n",
            "Y labels  I do n't want to be chosen .\n",
            "Y labels  I do hope you enjoy the rest of your day .\n",
            "Y labels  He tried it over and over again .\n",
            "Y labels  That 's pretty much everything you need to know .\n",
            "Y labels  I have work to do , so go away and leave me alone .\n",
            "Y labels  She suggested that I take him to the zoo .\n",
            "Y labels  You got here fast .\n",
            "Y labels  You 're a bad liar .\n",
            "Y labels  Are you good at tennis ?\n",
            "Y labels  You 're not helping me .\n",
            "Y labels  Please say hello to your wife .\n",
            "Y labels  Take this medicine after each meal .\n",
            "Y labels  Would you do me a favor ?\n",
            "Y labels  Do n't act like you do n't know how to dance .\n",
            "Y labels  Tell me all the details .\n",
            "Y labels  These gifts are for you .\n",
            "Y labels  I thought a lot about what you said .\n",
            "Y labels  My brother fell off a tree and broke his leg .\n",
            "Y labels  I ca n't really talk about it .\n",
            "Y labels  That sounds familiar .\n",
            "Y labels  She did n't tell me the truth .\n",
            "Y labels  Let 's go get snockered like we did last weekend .\n",
            "Y labels  You can borrow an umbrella if you need one .\n",
            "Y labels  You should not go there .\n",
            "Y labels  Mother Teresa was a Catholic nun who lived and worked in Calcutta , India .\n",
            "Y labels  I wonder if a human will ever be cloned .\n",
            "Y labels  I 'm ready now , Tom .\n",
            "Y labels  Staying at home is boring .\n",
            "Y labels  I bought a bottle of beer at the liquor store .\n",
            "Y labels  This semester I failed two students for plagiarism .\n",
            "Y labels  You should go .\n",
            "Y labels  The Sahara is the largest desert in the world .\n",
            "Y labels  How 's the weather ?\n",
            "Y labels  I do n't want to be told what to do .\n",
            "Y labels  I need a little help here .\n",
            "Y labels  He 's a strange guy .\n",
            "Y labels  Think it over and let me know what you decide .\n",
            "Y labels  Have you prepared everything for tomorrow ?\n",
            "Y labels  Buses in the country do n't usually come on time .\n",
            "Y labels  I ca n't remember my password .\n",
            "Y labels  Are n't you dressed yet ?\n",
            "Y labels  She is a student who studies very hard .\n",
            "Y labels  A woman was hanging the washing on the line .\n",
            "Y labels  It was kind of you to invite us .\n",
            "Y labels  The knife is not sharp .\n",
            "Y labels  You 're the teacher .\n",
            "Y labels  It 's time for us to go .\n",
            "Y labels  I 've been waiting all night .\n",
            "Y labels  I used to dream about being able to breathe underwater .\n",
            "Y labels  We will have to postpone the game .\n",
            "Y labels  A young man asked us if he could succeed as a public speaker .\n",
            "Y labels  The soldiers narrowly escaped death .\n",
            "torch.Size([64, 19])\n",
            "X input  Ne vous faites pas de souci au sujet de ce que j' ai fait !\n",
            "X input  Je ne veux pas que vous soyez contrariés .\n",
            "X input  La marijuana thérapeutique est légale dans cet État .\n",
            "X input  Je te suis redevable de ce que je suis maintenant .\n",
            "X input  Je m' ennuie . Faisons quelque chose !\n",
            "X input  Je ne m' y suis jamais fait prendre .\n",
            "X input  Comme vous êtes grand   !\n",
            "X input  J' entrerai .\n",
            "X input  Les gens les plus chéris au monde sont les gens spontanés .\n",
            "X input  Je serai couché à l' heure où tu rentreras .\n",
            "X input  Les étudiants sont revenus .\n",
            "X input  Nous étions excités en regardant le match .\n",
            "X input  Je n' aime pas tes amis .\n",
            "X input  Les emplois sont difficiles à trouver avec tant de gens au chômage .\n",
            "X input  Je vais me marier .\n",
            "X input  Ce n' est pas un élève ordinaire .\n",
            "X input  Ne nous oublie pas   !\n",
            "X input  Tu es venue trop tôt .\n",
            "X input  J' ai pensé que c' était une bonne idée .\n",
            "X input  Comment pourriez -vous être si cruel ?\n",
            "X input  Tu ne devrais pas boire d' eau croupie .\n",
            "X input  Je pense que nous devrions sortir d' ici .\n",
            "X input  Il fit d' elle sa femme .\n",
            "X input  C' est ma faute , pas la vôtre .\n",
            "X input  Le soleil disparut lentement sous l' horizon .\n",
            "X input  Vous auriez dû laisser Tom faire ce qu' il voulait .\n",
            "X input  Y a -t -il des places libres   ?\n",
            "X input  Il lui téléphone chaque soir .\n",
            "X input  Les oiseaux ont les yeux perçants .\n",
            "X input  Je n' ai jamais rencontré un musicien que je n' aimais pas .\n",
            "X input  Nous partons d' ici .\n",
            "X input  Je ne voulais pas que vous fassiez d' histoires .\n",
            "X input  Il s' est calé dans son siège de telle façon que je ne le voie pas .\n",
            "X input  Tu es un maniaque du travail .\n",
            "X input  Laisse -moi gagner pour une fois .\n",
            "X input  Assez de larmes . Ressaisis - toi .\n",
            "X input  Êtes -vous toujours effrayés ?\n",
            "X input  Tom est complètement obsédé par la bouffe . Pas étonnant que Mary l' ait largué   !\n",
            "X input  Sais - tu où elle est    ?\n",
            "X input  Se disputer n' a jamais conduit qui que ce soit où que ce soit .\n",
            "X input  Les pauvres gens étaient à la merci du cruel dictateur .\n",
            "X input  Vous avez beaucoup de chance d' avoir de tels amis .\n",
            "X input  Les Japonais ont tendance à penser de cette façon .\n",
            "X input  Je dois aider ces gens .\n",
            "X input  Je ne sais pas ce que je dois penser .\n",
            "X input  On ne vous tirera pas dessus .\n",
            "X input  Vous devrez travailler plus dur l' année prochaine .\n",
            "X input  Je déteste mon ordinateur .\n",
            "X input  Êtes -vous honnêtes ?\n",
            "X input  As - tu un appareil photo   ?\n",
            "X input  Quelque chose s' est produit ici , mais je ne sais pas quoi .\n",
            "X input  Arrête de te la péter !\n",
            "X input  Cela vous dérange -t -il que je retire mon chandail ?\n",
            "X input  Ça ne posera pas de problème .\n",
            "X input  Les Géants ont battu les Lions , hier .\n",
            "X input  Cela me semble intéressant   !\n",
            "X input  Je voulais te souhaiter mes bons vœux .\n",
            "X input  Pouvez -vous parler plus lentement   ?\n",
            "X input  Sont -ce là mes boucles d' oreille ?\n",
            "X input  Vous êtes celui qui m' a entraînée .\n",
            "X input  Je peux arriver en classe à temps , pensa -t -il .\n",
            "X input  Je sais que vous m' aimez .\n",
            "X input  Quiconque s' en soucie -t -il ?\n",
            "X input  Il est allé à la maison hier .\n",
            "y shape =  torch.Size([64, 16])\n",
            "Y labels  Do n't worry about what I did .\n",
            "Y labels  I do n't want you to be upset .\n",
            "Y labels  Medical marijuana is legal in this state .\n",
            "Y labels  I owe what I am today to you .\n",
            "Y labels  I 'm bored . Let 's do something .\n",
            "Y labels  I never got caught .\n",
            "Y labels  How tall you are !\n",
            "Y labels  I 'll go in .\n",
            "Y labels  The most beloved people in the world are the spontaneous .\n",
            "Y labels  I 'll be in bed by the time you get home .\n",
            "Y labels  The students have returned .\n",
            "Y labels  We were excited as we watched the game .\n",
            "Y labels  I do n't like your friends .\n",
            "Y labels  Jobs are hard to come by with so many people out of work .\n",
            "Y labels  I 'm going to get married .\n",
            "Y labels  He is no ordinary student .\n",
            "Y labels  Do n't forget about us !\n",
            "Y labels  You 've come too early .\n",
            "Y labels  I thought it was a good idea .\n",
            "Y labels  How could you be so cruel ?\n",
            "Y labels  You should n't drink stagnant water .\n",
            "Y labels  I think we should get out here .\n",
            "Y labels  He made her his wife .\n",
            "Y labels  It 's my fault , not yours .\n",
            "Y labels  The sun sank slowly below the horizon .\n",
            "Y labels  You should 've let Tom do what he wanted to do .\n",
            "Y labels  Are seats available ?\n",
            "Y labels  He calls her up every night .\n",
            "Y labels  Birds have sharp eyes .\n",
            "Y labels  I 've never met a musician that I did n't like .\n",
            "Y labels  We 're leaving here .\n",
            "Y labels  I did n't want you to make a fuss .\n",
            "Y labels  He scrunched down in his seat so that I would n't see him .\n",
            "Y labels  You are a workaholic .\n",
            "Y labels  Let me win for once .\n",
            "Y labels  That 's enough crying . Pull yourself together .\n",
            "Y labels  Are you still scared ?\n",
            "Y labels  Tom is utterly obsessed with food . No wonder Mary dumped him !\n",
            "Y labels  Do you know where she is ?\n",
            "Y labels  Arguing never got anyone anywhere .\n",
            "Y labels  The poor people were at the mercy of the cruel dictator .\n",
            "Y labels  You are very fortunate that you have such friends .\n",
            "Y labels  Japanese people tend to think that way .\n",
            "Y labels  I must help these people .\n",
            "Y labels  I do n't know what to think .\n",
            "Y labels  You wo n't be shot .\n",
            "Y labels  You will have to study harder next year .\n",
            "Y labels  I hate my computer .\n",
            "Y labels  Are you honest ?\n",
            "Y labels  Do you have a camera ?\n",
            "Y labels  Something happened here , but I do n't know what .\n",
            "Y labels  Come off it !\n",
            "Y labels  Do you mind if I take off my sweater ?\n",
            "Y labels  That wo n't be a problem .\n",
            "Y labels  The Giants beat the Lions yesterday .\n",
            "Y labels  It seems interesting to me .\n",
            "Y labels  I wanted to wish you well .\n",
            "Y labels  Could you speak more slowly ?\n",
            "Y labels  Are those my earrings ?\n",
            "Y labels  You 're the one who trained me .\n",
            "Y labels  I can make it to my class on time , he thought .\n",
            "Y labels  I know you love me .\n",
            "Y labels  Does anyone care ?\n",
            "Y labels  He went home yesterday .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One head of self attention\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size, mask = True):\n",
        "        super().__init__()\n",
        "        # Query, key, and value are all linear layers.\n",
        "        self.key = nn.Linear(n_embd, head_size, bias = False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias = False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias = False)\n",
        "        # create a tril matrix of ones\n",
        "        # PyTorch naming convention because the tril is not a parameter\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.mask = mask\n",
        "    def forward(self, x, query = None, key = None, value = None):\n",
        "        B,T,C = x.shape\n",
        "\n",
        "        if key is None:\n",
        "            key = x\n",
        "        if query is None:\n",
        "            query = x\n",
        "        if value is None:\n",
        "            value = x\n",
        "\n",
        "        k = self.key(key)   # (B, T, head_size)\n",
        "        q = self.query(query) # (B, T, head_size)\n",
        "        v = self.value(value) # (B, T, head_size)\n",
        "\n",
        "        # print(\"Head: x shape\",x.shape) # (64, 16, 384)\n",
        "        # print(\"Head: query shape\", q.shape) # (64, 16, 64)\n",
        "        # print(\"Head key shape\", k.shape) # (64, 19, 64)\n",
        "        # print(\"Head value shape\", v.shape) # (64, 19, 64)\n",
        "# 64 x 19 x 64\n",
        "# 64 x 64 x 16\n",
        "# w = 64 x 19 x 16\n",
        "# 64 x 16 x 19\n",
        "# v = 64 x 19 x 64\n",
        "# Required = 64 x 16 x 64\n",
        "        # Dot product the key and the query to get the weights\n",
        "        w = k @ q.transpose(-2, -1)  # (B,T,H) @ (B,H,T) = (B, T, T)\n",
        "\n",
        "        # Dividing by sqrt(head_size) for stability and making sure the variance stays close to zero\n",
        "        w = w * (C ** -0.5)\n",
        "\n",
        "        if self.mask:\n",
        "            w = w.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        w = F.softmax(w, dim = -1)\n",
        "        w = self.dropout(w)\n",
        "\n",
        "        out = w.transpose(-2, -1) @ v # (B, T, T) @ (B, T, C) = (B, T, C) cuz B stays the same so essentially its a (T, T) @ (T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, no_of_heads, head_size, mask = True):\n",
        "        super().__init__()\n",
        "        self.mask = mask\n",
        "        self.heads = nn.ModuleList([Head(head_size, self.mask) for _ in range(no_of_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, query = None, key = None, value = None):\n",
        "        if key is None:\n",
        "            key = x\n",
        "        if query is None:\n",
        "            query = x\n",
        "        if value is None:\n",
        "            value = x\n",
        "        out = torch.cat([head(x, query, key, value) for head in self.heads], dim = -1)\n",
        "        out = self.proj(out)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "        self.ln = nn.LayerNorm(n_embd)\n",
        "    def forward(self, x):\n",
        "            x = x + self.net(x)\n",
        "            x = self.ln(x)\n",
        "            return x\n",
        "\n",
        "class GlobalSelfAttention(nn.Module):\n",
        "    def __init__(self, n_embd, no_of_heads, mask = True):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // no_of_heads\n",
        "        self.mask = mask\n",
        "        self.mha = MultiHeadAttention(no_of_heads, head_size, self.mask)\n",
        "        self.ffwd = FeedForward(n_embd)\n",
        "        self.ln = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.mha(x)\n",
        "        x = self.ln(x)\n",
        "        return x\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, n_embd, no_of_heads):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // no_of_heads\n",
        "        self.ca = MultiHeadAttention(no_of_heads, head_size, mask = False)\n",
        "        self.ln = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        x = x + self.ca(x=x, query=x, key=context, value=context)\n",
        "        x = self.ln(x)\n",
        "        return x\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, n_embd, no_of_heads):\n",
        "        super().__init__()\n",
        "        self.sa = GlobalSelfAttention(n_embd, no_of_heads, mask = False)\n",
        "        self.ffn = FeedForward(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sa(x)\n",
        "        x = self.ffn(x)\n",
        "        return x\n",
        "# class PositionalEncoding(nn.Module):\n",
        "#     def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
        "#         super(PositionalEncoding, self).__init__()\n",
        "#         den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "#         pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "#         pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "#         pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "#         pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "#         pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "#         self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "#     def forward(self, token_embedding):\n",
        "#         return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[EncoderLayer(n_embd=n_embd, no_of_heads=no_of_heads) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets = None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device = device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, n_embd, no_of_heads):\n",
        "        super().__init__()\n",
        "        self.masked_attn = GlobalSelfAttention(n_embd, no_of_heads, mask = True)\n",
        "        self.crs_attn = CrossAttention(n_embd = n_embd, no_of_heads = no_of_heads)\n",
        "        self.ffn = FeedForward(n_embd)\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        x = self.masked_attn(x)\n",
        "        # print(\"CA: Shape of x\", x.shape)\n",
        "        # print(\"CA: Shape of context\", context.shape)\n",
        "        x = self.crs_attn(x = x, context = context)\n",
        "        # print(\"Decoder\")\n",
        "        x = self.ffn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.blocks = nn.Sequential(*[DecoderLayer(n_embd=n_embd, no_of_heads=no_of_heads) for _ in range(n_layer)])\n",
        "\n",
        "    def forward(self, x, context):\n",
        "    # `x` is token-IDs shape (batch, target_seq_len)\n",
        "        B, T = x.shape\n",
        "        tok_emb = self.token_embedding_table(x)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device = device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.dropout(x)\n",
        "        for i in range(n_layer):\n",
        "            x  = self.blocks[i](x, context)\n",
        "        # The shape of x is (batch_size, target_seq_len, d_model).\n",
        "        return x\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, vocab_size_src, vocab_size_tgt, n_embd):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(vocab_size_src)\n",
        "        self.decoder = Decoder(vocab_size_tgt)\n",
        "        self.final_layer = nn.Linear(n_embd, vocab_size_tgt)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        context, outputs = inputs\n",
        "        context = context.to(device)\n",
        "        outputs = outputs.to(device)\n",
        "        y_input = outputs[:, :-1]\n",
        "        y_labels = outputs[:, 1:]\n",
        "\n",
        "        context = self.encoder(context)\n",
        "        # print(\"output of context = \", context.shape)\n",
        "        # print(\"Y input \", y_input.shape)\n",
        "        x = self.decoder(x = y_input, context = context)  # (batch_size, target_len, d_model)\n",
        "        logits = self.final_layer(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# class BigramLanguageModel(nn.Module):\n",
        "#     def __init__(self, vocab_size):\n",
        "#         super().__init__()\n",
        "#         self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "#         self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "#         self.blocks = nn.Sequential(*[Block(n_embd, no_of_heads=no_of_heads) for _ in range(n_layer)])\n",
        "#         self.ln_f = nn.LayerNorm(n_embd)\n",
        "#         self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "#     def forward(self, idx, targets = None):\n",
        "#         B,T = idx.shape\n",
        "#         tok_emb = self.token_embedding_table(idx) #(B,T,C)\n",
        "#         pos_emb = self.position_embedding_table(torch.arange(T, device = device))\n",
        "#         x = tok_emb + pos_emb\n",
        "#         x = self.blocks(x)\n",
        "#         x = self.ln_f(x)\n",
        "#         logits = self.lm_head(x)\n",
        "#         if targets is None:\n",
        "#             loss = None\n",
        "#         else:\n",
        "#             # idx and targets are of shape (B,T)\n",
        "#             B,T,C = logits.shape\n",
        "#             logits = logits.view(B * T, C)\n",
        "#             targets = targets.view(B * T)\n",
        "#             loss = F.cross_entropy(logits, targets)\n",
        "#         return logits, loss\n",
        "\n",
        "#     def generate(self, idx, max_new_tokens):\n",
        "#         #idx is (B,T)\n",
        "#         for _ in range(max_new_tokens):\n",
        "#             # Cropping the idx to the last block_size tokens\n",
        "#             idx_cond = idx[:, -block_size:]\n",
        "#             logits, loss = self(idx_cond)\n",
        "#             logits = logits[:, -1, :] # Becomes (B, C)\n",
        "#             probs = F.softmax(logits, dim = -1)\n",
        "\n",
        "#             # Sampling from distribution\n",
        "#             idx_next = torch.multinomial(probs, num_samples = 1)\n",
        "#             idx = torch.cat((idx, idx_next), dim = 1)\n",
        "#         return idx\n",
        "\n",
        "# model = BigramLanguageModel(vocab_size)\n",
        "# m = model.to(device)\n",
        "# logits, loss = m(xb, yb)\n",
        "# print(loss)\n",
        "\n",
        "# idx = torch.zeros((1,1), dtype = torch.long, device = device) # stands for the new line token \\n\n",
        "# print(decode(m.generate(idx = idx, max_new_tokens = 100)[0].tolist()))\n"
      ],
      "metadata": {
        "id": "OfINxkfCZfun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit test for encoder\n",
        "sample_encoder = Encoder(vocab_size=vocab_size_src)\n",
        "# x,y = next(iter(train_dataloader))\n",
        "with torch.no_grad():\n",
        "    sample_encoder_output = sample_encoder(x)\n",
        "\n",
        "print(\"X shape = \", x.shape)\n",
        "print(sample_encoder_output.shape)  # Shape `(B,T,C)`.\n",
        "\n",
        "# Unit test for decoder\n",
        "print(sample_encoder_output.shape)\n",
        "sample_decoder = Decoder(vocab_size=vocab_size_tgt)\n",
        "\n",
        "print(\"y.shape = \", y.shape)\n",
        "with torch.no_grad():\n",
        "    output = sample_decoder(\n",
        "        x=y,\n",
        "        context=torch.randn((y.shape[0], y.shape[1], n_embd)))\n",
        "\n",
        "# Print the shapes.\n",
        "print(y.shape)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-tWYsvWuk2H",
        "outputId": "0ea7d4c0-2363-4e99-fd46-920f3b9fb6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape =  torch.Size([64, 19])\n",
            "torch.Size([64, 19, 384])\n",
            "torch.Size([64, 19, 384])\n",
            "y.shape =  torch.Size([64, 17])\n",
            "torch.Size([64, 17])\n",
            "torch.Size([64, 17, 384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit test for Transformer\n",
        "transformer = Transformer(vocab_size_src = vocab_size_src, vocab_size_tgt = vocab_size_tgt, n_embd = n_embd)\n",
        "output = transformer((x, y))\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5-jtuT07h9H",
        "outputId": "551ef328-ff02-475d-efe7-1ac2fd7b55c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "Head: x shape torch.Size([64, 19, 384])\n",
            "Head: query shape torch.Size([64, 19, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 19])\n",
            "output of context =  torch.Size([64, 19, 384])\n",
            "Y input  torch.Size([64, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "CA: Shape of x torch.Size([64, 16, 384])\n",
            "CA: Shape of context torch.Size([64, 19, 384])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Decoder\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "CA: Shape of x torch.Size([64, 16, 384])\n",
            "CA: Shape of context torch.Size([64, 19, 384])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Decoder\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "CA: Shape of x torch.Size([64, 16, 384])\n",
            "CA: Shape of context torch.Size([64, 19, 384])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Decoder\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "CA: Shape of x torch.Size([64, 16, 384])\n",
            "CA: Shape of context torch.Size([64, 19, 384])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Decoder\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "CA: Shape of x torch.Size([64, 16, 384])\n",
            "CA: Shape of context torch.Size([64, 19, 384])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Decoder\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 16, 64])\n",
            "Head value shape torch.Size([64, 16, 64])\n",
            "W shape = torch.Size([64, 16, 16])\n",
            "CA: Shape of x torch.Size([64, 16, 384])\n",
            "CA: Shape of context torch.Size([64, 19, 384])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Decoder\n",
            "torch.Size([64, 19])\n",
            "torch.Size([64, 17])\n",
            "torch.Size([64, 16, 14875])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_ca = CrossAttention(n_embd, no_of_heads)\n",
        "inp = torch.randn((64, 16, 384))\n",
        "outp = torch.randn((64, 19, 384))\n",
        "print(inp.shape)\n",
        "print(outp.shape)\n",
        "print(sample_ca(inp, outp).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PopLDrMqX_rk",
        "outputId": "19b82330-ffe4-4814-d60a-0f2bbf069930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 16, 384])\n",
            "torch.Size([64, 19, 384])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "Head: x shape torch.Size([64, 16, 384])\n",
            "Head: query shape torch.Size([64, 16, 64])\n",
            "Head key shape torch.Size([64, 19, 64])\n",
            "Head value shape torch.Size([64, 19, 64])\n",
            "W shape = torch.Size([64, 19, 16])\n",
            "torch.Size([64, 16, 384])\n"
          ]
        }
      ]
    }
  ]
}
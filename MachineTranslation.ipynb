{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjraMlFzRoolh49JP/Ciec",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjuns238/MachineTranslation/blob/main/MachineTranslation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mdoKzChr3DqN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import multi30k, Multi30k\n",
        "from torch.utils.data import Dataset, DataLoader,random_split\n",
        "from typing import Iterable, List\n",
        "import torchtext\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# # We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
        "# # Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
        "# multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
        "# multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
        "\n",
        "\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Installing dependencies\n",
        "# !pip install -U torchdata\n",
        "# !pip install -U spacy\n",
        "!pip install 'portalocker>=2.0.0'\n",
        "# !python -m spacy download en_core_web_sm\n",
        "!python -m spacy download fr_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euelWWGW4DW9",
        "outputId": "36d6f9eb-f402-4a5f-f13d-ce27fb2dc9a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n",
            "Collecting fr-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from fr-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.5)\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('fr_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "block_size = 256\n",
        "learning_rate = 1e-2\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "eval_iters = 200\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "n_embd = 384\n",
        "dropout = 0.2\n",
        "no_of_heads = 6\n",
        "n_layer = 6\n",
        "device\n",
        "SRC_LANGUAGE = 'Fr'\n",
        "TGT_LANGUAGE = 'En'"
      ],
      "metadata": {
        "id": "1oMLIZgl3Joe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/eng-fra.txt\", sep=\"\\t\", header=None)\n",
        "data = data.set_axis(['En','Fr'], axis = 1) # Rename indices\n",
        "data.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UBZLUOIp3Ltw",
        "outputId": "64a6841a-75ba-465f-e226-a70c3c7339cf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                       En  \\\n",
              "135837  A carbon footprint is the amount of carbon dio...   \n",
              "135838  Death is something that we're often discourage...   \n",
              "135839  Since there are usually multiple websites on a...   \n",
              "135840  If someone who doesn't know your background sa...   \n",
              "135841  It may be impossible to get a completely error...   \n",
              "\n",
              "                                                       Fr  \n",
              "135837  Une empreinte carbone est la somme de pollutio...  \n",
              "135838  La mort est une chose qu'on nous décourage sou...  \n",
              "135839  Puisqu'il y a de multiples sites web sur chaqu...  \n",
              "135840  Si quelqu'un qui ne connaît pas vos antécédent...  \n",
              "135841  Il est peut-être impossible d'obtenir un Corpu...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b1830bd-52fe-4c01-bdc7-4f1e2ae4d90f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>En</th>\n",
              "      <th>Fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>135837</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135838</th>\n",
              "      <td>Death is something that we're often discourage...</td>\n",
              "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135839</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135840</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135841</th>\n",
              "      <td>It may be impossible to get a completely error...</td>\n",
              "      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b1830bd-52fe-4c01-bdc7-4f1e2ae4d90f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b1830bd-52fe-4c01-bdc7-4f1e2ae4d90f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b1830bd-52fe-4c01-bdc7-4f1e2ae4d90f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-10318345-712c-4cea-ab4a-4f0932953e52\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10318345-712c-4cea-ab4a-4f0932953e52')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-10318345-712c-4cea-ab4a-4f0932953e52 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"En\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\",\n          \"It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning, we might be able to minimize errors.\",\n          \"Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"La mort est une chose qu'on nous d\\u00e9courage souvent de discuter ou m\\u00eame de penser mais j'ai pris conscience que se pr\\u00e9parer \\u00e0 la mort est l'une des choses que nous puissions faire qui nous investit le plus de responsabilit\\u00e9. R\\u00e9fl\\u00e9chir \\u00e0 la mort clarifie notre vie.\",\n          \"Il est peut-\\u00eatre impossible d'obtenir un Corpus compl\\u00e8tement d\\u00e9nu\\u00e9 de fautes, \\u00e9tant donn\\u00e9e la nature de ce type d'entreprise collaborative. Cependant, si nous encourageons les membres \\u00e0 produire des phrases dans leurs propres langues plut\\u00f4t que d'exp\\u00e9rimenter dans les langues qu'ils apprennent, nous pourrions \\u00eatre en mesure de r\\u00e9duire les erreurs.\",\n          \"Puisqu'il y a de multiples sites web sur chaque sujet, je clique d'habitude sur le bouton retour arri\\u00e8re lorsque j'atterris sur n'importe quelle page qui contient des publicit\\u00e9s surgissantes. Je me rends juste sur la prochaine page propos\\u00e9e par Google et esp\\u00e8re tomber sur quelque chose de moins irritant.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='fr_core_news_sm')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "# helper function to yield list of tokens\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter[language]:\n",
        "        yield token_transform[language](data_sample)\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    print(ln)\n",
        "    # Training data Iterator\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(data, ln),\n",
        "                                                    min_freq=1,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)\n",
        "\n",
        "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS6lnvtw3OKh",
        "outputId": "b27c9814-8e91-41a5-9978-274e29f2ed4c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fr\n",
            "En\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab_transform[\"En\"].lookup_token(200))\n",
        "print(vocab_transform[\"En\"].lookup_indices([\"left\"]))"
      ],
      "metadata": {
        "id": "4GlvmB6N3RP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d33766-5e8a-4714-ace7-27ea28d5cba5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "left\n",
            "[200]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Encode a sentence\n",
        "def encode_sentence(sentence: str, language: str, tokenizer, vocab) -> List[int]:\n",
        "    # Tokenize the sentence\n",
        "    tokens = tokenizer(sentence)\n",
        "    # Convert tokens to indices using vocabulary\n",
        "    indices = vocab_transform[language].lookup_indices(tokens)\n",
        "    return indices\n",
        "\n",
        "# Step 2: Decode a sequence\n",
        "def decode_sequence(indices: List[int], language: str, vocab) -> str:\n",
        "    # Convert indices to tokens\n",
        "    tokens = [vocab_transform[language].lookup_token(index) for index in indices]\n",
        "    # Remove <bos> and <eos> tokens if present\n",
        "    if tokens[0] == '<bos>':\n",
        "        tokens = tokens[1:]\n",
        "    if tokens[-1] == '<eos>':\n",
        "        tokens = tokens[:-1]\n",
        "    # Convert tokens to a sentence\n",
        "    sentence = ' '.join(tokens)\n",
        "    return sentence\n",
        "\n",
        "# Example usage\n",
        "sentence = \"Je suis froid\"\n",
        "encoded = encode_sentence(sentence, SRC_LANGUAGE, token_transform[SRC_LANGUAGE], vocab_transform[SRC_LANGUAGE])\n",
        "decoded = decode_sequence(encoded, SRC_LANGUAGE, vocab_transform[SRC_LANGUAGE])\n",
        "print(\"Original sentence:\", sentence)\n",
        "print(\"Encoded sequence:\", encoded)\n",
        "print(\"Decoded sentence:\", decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B2aBecu3ZXu",
        "outputId": "309d1243-372f-4e9c-d2ea-a725c7322faf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence: Je suis froid\n",
            "Encoded sequence: [6, 34, 448]\n",
            "Decoded sentence: Je suis froid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    # src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    # tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ],
      "metadata": {
        "id": "K530InMa3br6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sen = data[\"Fr\"][0]\n",
        "print(sen)\n",
        "outputText = text_transform[TGT_LANGUAGE](sen.rstrip(\"\\n\"))\n",
        "print(outputText)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu8cT3jefz-J",
        "outputId": "270158a4-fb9a-4d91-a5d3-5b40c9492103"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Va !\n",
            "tensor([  2,   0, 127,   3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, inputText, outputText):\n",
        "        self.inputText = inputText\n",
        "        self.outputText = outputText\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputText)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.inputText[idx]\n",
        "        outputText = self.outputText[idx]\n",
        "        outputText = outputText[:, :block_size]\n",
        "    # pt = pt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
        "\n",
        "\n",
        "        outputText = text_transform[TGT_LANGUAGE](outputText.rstrip(\"\\n\"))\n",
        "        y_inputs = outputText[:, :-1]  # Drop the [END] tokens\n",
        "        y_labels = outputText[:, 1:]   # Drop the [START] tokens\n",
        "        # sample = encode_sentence(sample, SRC_LANGUAGE, token_transform[SRC_LANGUAGE], vocab_transform[SRC_LANGUAGE])\n",
        "        # output = encode_sentence(output, TGT_LANGUAGE, token_transform[TGT_LANGUAGE], vocab_transform[TGT_LANGUAGE])\n",
        "\n",
        "        return (x, y_inputs), y_labels\n",
        "\n",
        "dataset = CustomDataset(data[\"Fr\"], data[\"En\"])\n",
        "\n",
        "# train_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "VHHPSEEv3epu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in dataset:\n",
        "    print(\"x = \", x)\n",
        "    print(\"y = \", y)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "WrhwjMSwfchZ",
        "outputId": "81c678de-85bd-40e9-91c1-8f655ead7f62"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "string indices must be integers",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-92755d7f12d9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-bce2e1945026>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputText\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutputText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputText\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputText\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputText\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, validation split\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# # Create a DataLoader to iterate over batches of data and performing preprocessing\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "XD6-Dd2wY2CP"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in train_dataloader:\n",
        "    print(\"x = \", x)\n",
        "    for item in x:\n",
        "        print(decode_sequence(item, SRC_LANGUAGE, vocab_transform[SRC_LANGUAGE]))\n",
        "    print(\"y = \", y)\n",
        "    for item in y:\n",
        "        print(decode_sequence(item, TGT_LANGUAGE, vocab_transform[TGT_LANGUAGE]))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCY4E-m0S1-v",
        "outputId": "7afc446f-f23c-4ca7-efa7-4dc4dd91d462"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =  [tensor([  2,   6,  12,  31, 684,   8,  57, 298,   5,  98, 200,   4,   3]), tensor([   2,  391,   37, 1762,  554,  324,   17,   18,  240,  745,   13, 2255,\n",
            "         210,   69,    4,    3]), tensor([  2,  45,  12, 503,   8,  14, 252,   4,   3]), tensor([   2,   41,  116,   25,  120,    5, 5862,   14,  832,    4,    3]), tensor([  2,  73, 620,  32,   8,  42,  37, 145,  19, 215,  35,  18,   5, 242,\n",
            "          7,   3]), tensor([   2,    6,  183,   10,   23,  177,   93,   10,   23,   12,  533,    8,\n",
            "         232,    5,  877, 2073,    4,    3]), tensor([   2,    6,   20,  179,    8,   11, 1226,   38,  141, 7444,   35,   14,\n",
            "         238,    4,    3]), tensor([  2,   6,  12,  34,   8, 551,   5, 984,  29,  10,  18, 562,   4,   3]), tensor([   2,  224,  361,   12, 1762,   97,   60, 5262,    4,    3]), tensor([ 2,  6, 55, 57, 74,  4,  3]), tensor([   2,    6, 2489,    5,   18,  132,    4,    3]), tensor([   2,  599,  119,  160,   18,   67, 1844,    4,    3]), tensor([    2, 11818,   230,  4875,    82,     7,     3]), tensor([    2,   175,    23,    20,  4030,     8,    51,   447,    17,    37,\n",
            "            9,   715,    10,    23, 15168,     4,     3]), tensor([  2,   6, 937, 967, 103,  29,  10,  79, 636,   4,   3]), tensor([   2,   88, 9426, 7840,   10,   13, 1747, 2365, 5176,    4,    3]), tensor([  2, 124,  96,  32, 570, 559,   7,   3]), tensor([   2, 2388,   30, 1549,   86,  141,    4,    3]), tensor([   2,   84,  208,   77, 3719,    4,    3]), tensor([   2,   41,  116, 1552,   11,   52,  105,    4,    3]), tensor([  2, 350,  67,  32, 480,   7,   3]), tensor([   2,   24,   22, 4425,   13, 2306,    5,   19, 1828,    4,    3]), tensor([   2,   26,  117,  125,   38, 1470,   11,   19, 3266,   50, 6660,    4,\n",
            "           3]), tensor([  2,  41, 116,  87,   4,   3]), tensor([   2,  460,   21,   18,   15, 1581,    4,    3]), tensor([   2,   40,   15,  364,   21,  622,    5, 6105,    4,    3]), tensor([   2,   41,  107, 3475,  446,    4,    3]), tensor([  2,  16,  56, 150,  42,  37, 603, 180, 289,   4,   3]), tensor([    2,    41,   561, 19498,    30,   952,     4,     3]), tensor([    2,    24,    22,    21, 14812,  3111,     4,     3]), tensor([   2,   24,   22, 1771,   48,   98,  414,  336,    4,    3]), tensor([   2,   40,   15,  570,   30, 2787,  159,    4,    3]), tensor([   2,   24,   22,  102, 1232,  106,  269,   17,  182,  579,    4,    3]), tensor([   2, 1427,  548,   68,  133, 2130,    4,    3]), tensor([  2,  24,  52,  34, 355,  17, 959,   4,   3]), tensor([   2,   84, 1805,    9,   82,  760,    7,    3]), tensor([ 2, 24, 25, 55, 30, 39,  3]), tensor([   2,  586,  392,   15, 1189,   87,  875,   50, 7737,    4,    3]), tensor([  2,  24, 346, 170, 830,   5, 581,   4,   3]), tensor([    2,     6,    34, 11238,     4,     3]), tensor([  2,   6,  12,  34,  97, 355,  25, 994,   4,   3]), tensor([   2,   40,   12, 3474,    8,   42,   37, 2600,   13,  365,    4,    3]), tensor([   2,   24, 1098,   10,   47, 1007,    5,   13, 1487,    4,    3]), tensor([   2, 9781,  119,  419,   39,    3]), tensor([   2,   65,  546,  154, 1109,   27, 4074,    4,    3]), tensor([    2,   640,    28,    23,    17,    33,    54,   272,    17, 14410,\n",
            "           13,   499,    11,    30,   215,    62,    54,  8611,     7,     3]), tensor([   2,   45,   89,  583,   62,   49,   15, 4606,    4,    3]), tensor([    2,   195,  5902,   210,  9241,    17,   206,  9501,   210, 10535,\n",
            "            4,     3]), tensor([  2,  45, 466, 191,  27, 105,  61, 335, 585,   4,   3]), tensor([  2,  24, 357, 201,  83,  33,  34, 197, 203,   4,   3]), tensor([    2,    88,  8746, 11403,  9179,   320,    13,  1227,     4,     3]), tensor([   2,    6, 2195,   26,  222,    4,    3]), tensor([   2,   16,   12, 1304,   97,  166, 2271,    4,    3]), tensor([   2,   16,   25,   15,  180,  323,   42,   37,   25,   15, 9104,    4,\n",
            "           3]), tensor([   2,   16,   49,   15, 1160,   31, 8113,   27,   87,    4,    3]), tensor([   2,  218,   32,   11,   13, 1553,    5,  284,   21,    7,    3]), tensor([   2, 1166,   48,  170,  300,   17,  184,   39,    3]), tensor([   2, 8323,   28,   23,  126,    7,    3]), tensor([   2,   46,    9,   14,  549, 1151,   10,   79, 4916,   97,    5,   92,\n",
            "        1693,    4,    3]), tensor([   2,   26,   70,  250,   20,  328,    8, 3940,    4,    3]), tensor([   2,   46,    9,   30,  331,    5, 4178,    4,    3]), tensor([  2,  46,  63, 525,  29, 353,  79, 177, 118,   4,   3]), tensor([    2,    16,     9,   938,    11, 11596,    25, 15309,     4,     3]), tensor([   2,    6,  440,   10,   66, 3001,    4,    3])]\n",
            "Je ne me souviens pas du nom de cette personne .\n",
            "S' il devait arriver tard , vous pouvez commencer la conférence sans lui .\n",
            "Tu ne vas pas le croire .\n",
            "Nous sommes en train de rédiger le rapport .\n",
            "Ne pensez -vous pas qu' il soit l' heure pour vous de partir ?\n",
            "Je pensais que tu avais dit que tu ne pouvais pas manger de poisson cru .\n",
            "Je n' arrive pas à joindre les deux bouts pour le moment .\n",
            "Je ne suis pas sûre de suivre ce que vous dites .\n",
            "Cette lettre ne devait jamais être envoyée .\n",
            "Je veux du temps .\n",
            "Je tente de vous parler .\n",
            "Dis -moi où vous êtes allées .\n",
            "Neuf heures conviendrait -il ?\n",
            "Si tu n' étudies pas plus dur , il est certain que tu échoueras .\n",
            "Je fus surprise par ce que j' appris .\n",
            "Les statistiques montrent que la population mondiale augmente .\n",
            "L' avez -vous essayé auparavant ?\n",
            "Écrivez une ligne sur deux .\n",
            "Ce fut très douloureux .\n",
            "Nous sommes prêtes à y aller .\n",
            "Y êtes -vous prêt ?\n",
            "J' ai poursuivi la lecture de l' ouvrage .\n",
            "Tom aime tous les légumes à l' exception des choux .\n",
            "Nous sommes ici .\n",
            "Quelqu' un vous a vues .\n",
            "Elle a trouvé un emploi de dactylo .\n",
            "Nous avons voyagé ensemble .\n",
            "Il se peut qu' il ait eu raison .\n",
            "Nous allons essuyer une tempête .\n",
            "J' ai un stimulateur cardiaque .\n",
            "J' ai grandi dans cette petite ville .\n",
            "Elle a essayé une troisième fois .\n",
            "J' ai vraiment apprécié ton aide , hier après-midi .\n",
            "Tes cheveux sont trop longs .\n",
            "J' y suis allé , également .\n",
            "Ce siège est -il libre ?\n",
            "J' en veux une !\n",
            "Notre famille a vécu ici durant des générations .\n",
            "J' adore ta façon de penser .\n",
            "Je suis sobre .\n",
            "Je ne suis jamais allé en Amérique .\n",
            "Elle ne voulut pas qu' il quitte la pièce .\n",
            "J' ignorais que nous avions de la compagnie .\n",
            "Souhaitez -moi chance !\n",
            "Le prix va continuer d' augmenter .\n",
            "Pourrais - tu , je te prie , re-programmer la réunion à une heure qui te convienne ?\n",
            "Tu es celui qui m' a entraînée .\n",
            "À vaincre sans péril , on triomphe sans gloire .\n",
            "Tu ferais mieux d' aller au lit immédiatement .\n",
            "J' ignore simplement si je suis assez bonne .\n",
            "Les eaux usées polluent souvent la mer .\n",
            "Je verrai Tom demain .\n",
            "Il ne tient jamais ses promesses .\n",
            "Il en a eu davantage qu' il en a négocié .\n",
            "Il m' a fallu me tailler d' ici .\n",
            "Êtes -vous à la recherche de quelqu' un ?\n",
            "Va dans ta chambre , maintenant !\n",
            "Savais - tu cela ?\n",
            "C' est le dernier message que j' envisage jamais de t' envoyer .\n",
            "Tom et Marie n' étaient pas impressionnés .\n",
            "C' est une question de priorités .\n",
            "C' était exactement ce dont j' avais besoin .\n",
            "Il est né à Athènes en 1956 .\n",
            "Je savais que ça arriverait .\n",
            "y =  [tensor([    2,   246,   272, 12302,    18,     4,     3]), tensor([   2,  146,   51,   82,  874,  225,   22,    6,  247,  435,    8, 2077,\n",
            "         262,   46,    4,    3]), tensor([  2,  16, 212,  10, 158,  23,   4,   3]), tensor([   2,   36,   32,   20,    8, 3599,   15,  797,    8,  706,  108,    4,\n",
            "           3]), tensor([  2,  34,  10,   6,  55,  23,  14,  59,   6, 200,   9,   3]), tensor([   2,    5,  126,    6,  162,    6,   94,   10,  177, 2539,  626,    4,\n",
            "           3]), tensor([   2,    5,   58,   10,  118, 2818,  350,  108,    4,    3]), tensor([  2,   5,  29,  30, 150,   5, 806,  47,   6,  32, 521,   4,   3]), tensor([   2,   74,  348,   25,  106, 1096,    7,   31,  841,    4,    3]), tensor([ 2,  5, 33, 59,  4,  3]), tensor([  2,   5,  29, 428,   7, 145,   7,   6,   4,   3]), tensor([  2, 414,  18, 196,   6, 148,   4,   3]), tensor([   2,  224, 4401,  754,   31,   49,  116,    9,    3]), tensor([   2,  146,    6,   13,   10,  405,  937,   22,    6,   56, 1500,   26,\n",
            "         150,    4,    3]), tensor([  2,   5,  25, 450,  90,  47,   5, 857,   4,   3]), tensor([    2, 11004,   383,    21,     8,  1547,    15,     8,   370,    12,\n",
            "         3069,     4,     3]), tensor([  2, 159,   6, 352,  28, 169,   9,   3]), tensor([   2, 1515,   43,  226,  242,  976,    4,    3]), tensor([   2,   40,   25,   63, 3089,    4,    3]), tensor([  2,  36,  32, 314,   7,  53,   4,   3]), tensor([ 2, 81,  6, 67, 26, 23,  9,  3]), tensor([   2,    5, 1735,  444,    8,  168,    4,    3]), tensor([   2,   19,  404,   49, 1328, 2037, 6898,    4,    3]), tensor([ 2, 36, 41, 62,  4,  3]), tensor([   2, 1292,  201,    6,    4,    3]), tensor([   2,   35,  277, 4932,   76,   11, 4372,    4,    3]), tensor([   2,   36, 2168,  366,    4,    3]), tensor([  2,  17, 247,  24,  98, 116,   4,   3]), tensor([  2,  36,  41,  83,   7,  24,  11, 908,   4,   3]), tensor([   2,    5,   66,  107,   11, 9231,    4,    3]), tensor([   2,    5, 1212,   67,   20,   28,  456,  518,    4,    3]), tensor([   2,   35,  352,   11, 1629,   59,    4,    3]), tensor([   2,    5,   97, 3318,   27,  100,  194,  528,    4,    3]), tensor([  2, 280, 484,  12, 112, 156,   4,   3]), tensor([  2,   5, 148,  22, 112,   4,   3]), tensor([  2, 110,  28, 801, 330,   9,   3]), tensor([ 2,  5, 33, 79,  4,  3]), tensor([   2,  461,  392,   77,  622,   62,   26, 5508,    4,    3]), tensor([  2,   5, 149,   8, 144,   6,  55,   4,   3]), tensor([   2,    5,   29, 4692,    4,    3]), tensor([  2,   5,  24, 106,  98,   7, 914,   4,   3]), tensor([  2,  35,  39,  10,  33,  46,   7, 190,   8, 182,   4,   3]), tensor([  2,   5,  39,  10,  45,  72,  65, 547,   4,   3]), tensor([   2, 8219,   18,  730,    4,    3]), tensor([   2, 2177,   73, 1223,    7,   53,   67,    4,    3]), tensor([   2,  295,    6,  199, 6402,    8,  391,   48,   11,   59,   21,   12,\n",
            "        2592,   26,    6,    9,    3]), tensor([   2,   16,   32,    8,   79,  154, 1893,   18,    4,    3]), tensor([   2,  846, 7724,   22,  254, 3212,    4,    3]), tensor([  2,  16,  80, 161,  53,   7, 297,  48, 354,   4,   3]), tensor([  2,   5,  78,  13,  10,  45, 105,   5,  29,  86, 205,   4,   3]), tensor([    2, 10944,   301,  7430,     8,  2839,     4,     3]), tensor([  2,   5,  56,  92,  19, 208,   4,   3]), tensor([   2,   17,  106, 1187,   52,  374,    4,    3]), tensor([   2,   17,  107,   99,  115,   51, 5341,   26,    4,    3]), tensor([  2,   5,  65,   7,  69, 214,  87,  62,   4,   3]), tensor([  2,  81,   6, 271,  26, 379,   9,   3]), tensor([  2, 572,   7,  27, 182, 108, 127,   3]), tensor([  2, 131,   6,  45,  21,   9,   3]), tensor([   2,   74,   12,    8,  138, 1007,    5,  209,  349,    7, 1108,    7,\n",
            "           6,    4,    3]), tensor([  2,  19,  60, 109,  71,  10, 965,   4,   3]), tensor([   2,   40,   14,   11,  319,   15, 7449,    4,    3]), tensor([  2,  75,  25,  78,  47,   5, 610,   4,   3]), tensor([   2,   17,   25,  568,   20, 7819,   20, 9932,    4,    3]), tensor([  2,   5, 303,  28,  89, 315,   4,   3])]\n",
            "His name eludes me .\n",
            "If he should arrive late , you may start the conference without him .\n",
            "You wo n't believe it .\n",
            "We 're in the process of writing the report now .\n",
            "Do n't you think it 's time you left ?\n",
            "I thought you said you could n't eat raw fish .\n",
            "I ca n't make ends meet now .\n",
            "I 'm not sure I follow what you 're saying .\n",
            "This letter was never meant to be sent .\n",
            "I want time .\n",
            "I 'm trying to talk to you .\n",
            "Tell me where you went .\n",
            "Would 9 o'clock be all right ?\n",
            "If you do n't study harder , you 'll fail for sure .\n",
            "I was surprised by what I learned .\n",
            "Statistics show that the population of the world is increasing .\n",
            "Have you tried this before ?\n",
            "Write on every other line .\n",
            "It was very painful .\n",
            "We 're ready to go .\n",
            "Are you up for it ?\n",
            "I continued reading the book .\n",
            "Tom likes all vegetables except cabbage .\n",
            "We are here .\n",
            "Somebody saw you .\n",
            "She found employment as a typist .\n",
            "We traveled together .\n",
            "He may have been right .\n",
            "We are going to have a storm .\n",
            "I 've got a pacemaker .\n",
            "I grew up in this small town .\n",
            "She tried a third time .\n",
            "I really appreciated your help yesterday afternoon .\n",
            "Your hair is too long .\n",
            "I went , too .\n",
            "Is this seat open ?\n",
            "I want one .\n",
            "Our family has lived here for generations .\n",
            "I love the way you think .\n",
            "I 'm sober .\n",
            "I have never been to America .\n",
            "She did n't want him to leave the room .\n",
            "I did n't know we had company .\n",
            "Wish me luck .\n",
            "Prices will continue to go up .\n",
            "Could you please reschedule the meeting at a time that is convenient for you ?\n",
            "You 're the one who trained me .\n",
            "Nothing ventured , nothing gained .\n",
            "You 'd better go to bed at once .\n",
            "I just do n't know if I 'm good enough .\n",
            "Sewage often pollutes the ocean .\n",
            "I 'll see Tom tomorrow .\n",
            "He never keeps his word .\n",
            "He got more than he bargained for .\n",
            "I had to get away from here .\n",
            "Are you looking for someone ?\n",
            "Go to your room now !\n",
            "Did you know that ?\n",
            "This is the last message I ever plan to send to you .\n",
            "Tom and Mary were n't impressed .\n",
            "It 's a matter of priorities .\n",
            "That was just what I needed .\n",
            "He was born in Athens in 1956 .\n",
            "I knew this would happen .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8OpeeoU1dqvt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}